# Rate Limiter

A simple rate limiter implementation in Go without external dependencies.

## Features

### ğŸ¯ Core Rate Limiting
- âœ… In-memory storage (Go maps) - no database required
- âœ… Thread-safe with channel-based synchronization
- âœ… Concurrent request handling without race conditions
- âœ… Zero external dependencies - pure Go standard library

### ğŸ“Š Multiple Rate Limiting Strategies
- âœ… **Fixed Window Counter** - Simple, memory efficient
- âœ… **Sliding Window Log** - Accurate, smooth limiting

### ğŸ”‘ Flexible Client Identification
- âœ… IP-based rate limiting
- âœ… API key-based rate limiting
- âœ… Custom header extraction
- âœ… Per-client custom limits

### ğŸ’ Premium Tier Support
- âœ… Configurable limits per API key
- âœ… Premium users: 100 req/min
- âœ… Basic users: 10 req/min (default)
- âœ… Easy tier configuration

### ğŸ”Œ Easy Integration
- âœ… HTTP middleware for `net/http`
- âœ… Plug-and-play with existing servers
- âœ… Clean API with minimal code changes

### âœ… Production-Ready
- âœ… Comprehensive unit tests
- âœ… Race condition testing
- âœ… Clean architecture (Strategy + Middleware patterns)
- âœ… Lightweight and fast
- âœ… Docker


## Prerequisites

- Go 1.16 or higher

## Installation

```bash
git clone <repository-url>
cd rate-limiter
go mod tidy
go build -o rate-limiter ./cmd/server
./rate-limiter
```

# Project Structure
````
rate-limiter/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ server/
â”‚       â””â”€â”€ main.go              # Application entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ middleware.go        # HTTP middleware for rate limiting
â”‚   â””â”€â”€ rateLimiter/
â”‚       â”œâ”€â”€ rateLimiter.go       # Core rate limiter implementation
â”‚       â”œâ”€â”€ strategy.go          # Rate limiting strategies
â”‚       â””â”€â”€ rateLimiter_test.go  # Unit tests
â”œâ”€â”€ go.mod                       # Go module file
â””â”€â”€ README.md                    # Project documentation
````

# Testing
1. go test ./internal/rateLimiter/...
2. go test -v -cover ./internal/rateLimiter/...

# Architecture
- Strategy Pattern: Implemented to allow pluggable rate limiting algorithms. This makes it easy to switch between different strategies or add new ones without modifying existing code.
- Middleware Approach: Rate limiting is implemented as HTTP middleware, allowing easy integration into any HTTP server with minimal code changes.
- In-Memory Storage: Uses Go maps for simplicity and speed. Suitable for single-instance deployments. For distributed systems, this could be extended to use Redis or similar.
- Clean Architecture: Separation of concerns with:
cmd/ for application entry points
internal/ for implementation details (not importable by external packages)
middleware/ for HTTP integration layer
rateLimiter/ for core business logic


# API Usage Example
```
Test Basic Tier:
GET http://localhost:8080/api/hello
Header: X-API-Key: basic-user-123

Response (1st-10th request):
{
  "message": "Hello! You are within rate limits.",
  "time": "2025-01-15T10:30:00Z",
  "user_tier": "basic",
  "rate_limit": "10 requests/minute"
}

Response (11th request - Rate Limited):
{
  "error": "rate limit exceeded",
  "tier": "basic",
  "limit": "10 requests/minute"
}

Test Premium Tier:
GET http://localhost:8080/api/hello
Header: X-API-Key: premium-api-key

Response (1st-100th request):
{
  "message": "Hello! You are within rate limits.",
  "time": "2025-01-15T10:30:00Z",
  "user_tier": "premium",
  "rate_limit": "100 requests/minute"
}

Response (101st request - Rate Limited):
{
  "error": "rate limit exceeded",
  "tier": "premium",
  "limit": "100 requests/minute"
}
```

## Per-Client Configuration âœ¨

### Premium Tier Example

```
rl := rateLimiter.NewRateLimiter(defaultStrategy)

// Set premium tier: 100 requests/minute
rl.SetPremiumClient("premium-api-key", 100, time.Minute)

// Basic users get default limit (10 req/min)

# Premium user (100 req/min)
curl -H "X-API-Key: premium-api-key" http://localhost:8080/api

# Basic user (10 req/min default)
curl -H "X-API-Key: any-other-key" http://localhost:8080/api
````

## Key Benefits of This Approach

âœ… **No mutex needed** - uses existing channel pattern  
âœ… **Thread-safe** - all operations serialized through channel  
âœ… **Simple** - just adds `premiumClients` map lookup  
âœ… **Consistent** - follows your existing architecture  
âœ… **Meets Requirement #3** - premium clients get 100 req/min

## How It Works

```
// Request flow:
// 1. Request comes in with API key
// 2. Allow() called with API key as key
// 3. Channel operation checks if key is in premiumClients map
// 4. If premium â†’ use premium strategy (100 req/min)
// 5. If not premium â†’ use default strategy (10 req/min)
````

# Rate Limiting Algorithms

### Fixed Window Counter

- **Description:** Counts requests in fixed time windows
- **How it works:** Resets the counter at the start of each time window
- **Pros:**
    - Simple implementation
    - Low memory usage (only stores count + timestamp)
    - Fast O(1) lookup
- **Cons:**
    - Can allow bursts at window boundaries
    - Example: If window = 1 minute, user can make 10 requests at 00:59 and another 10 at 01:01 (20 requests in 2 seconds)



# Request Processing Flow

```
Client sends HTTP request
   â†“
Server receives request on :8080
   â†“
RateLimitMiddleware intercepts
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Extract API Key from X-API-Key headerâ”‚ â† Layer 1: HTTP Gateway
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Call limiter.Allow(apiKey)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. RateLimiter.Allow() sends request    â”‚
â”‚    to process() goroutine via channel   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. process() checks premiumClients map  â”‚
â”‚    â€¢ If key = "premium-api-key"         â”‚ â† Layer 2: Router/Orchestrator
â”‚      â†’ Use premium strategy (100/min)   â”‚
â”‚    â€¢ Otherwise                          â”‚
â”‚      â†’ Use default strategy (10/min)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Strategy.Allow() checks buckets map  â”‚
â”‚    â€¢ Get or create bucket for this key  â”‚  â† Layer 3: Business Logic
â”‚    â€¢ Check if window expired            â”‚
â”‚    â€¢ Increment count                    â”‚
â”‚    â€¢ Return true/false                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Send result back via response channelâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Middleware receives result           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
   â”œâ”€ If ALLOWED (true)
   â”‚    â†“
   â”‚  Continue to handler (/api/hello or /api/status)
   â”‚    â†“
   â”‚  Handler executes
   â”‚    â†“
   â”‚  Response sent with 200 OK
   â”‚
   â””â”€ If DENIED (false)
        â†“
      Return 429 Too Many Requests
        â†“
      Send JSON error response
      
      
Middleware â†’ HTTP concerns
RateLimiter â†’ Routing concerns  
Strategy â†’ Algorithm concerns

HTTP Request â†’ Middleware â†’ RateLimiter â†’ Strategy
                    â†“           â†“                    â†“
                Extract    Route to strategy    Implement rate limiting algorithm
                identifier
                    â†“           â†“                                        â†“
                 Panggil      Manage premium vs default clients     Track request counts per client
                 Allow(),
                 send http
                 
      
```


# Assumptions
1. Single Instance: Current implementation assumes a single server instance. For distributed systems, you'll need a shared cache (e.g., Redis).
2. Client Identification: Clients are identified by IP address or custom headers. Modify the middleware to change identification logic.
3. Memory Limits: In-memory storage is suitable for moderate traffic. High-traffic scenarios should use persistent storage.
4. Time Synchronization: Assumes server time is accurate. Clock skew can affect rate limiting accuracy.

# Limitations
1. No Persistence: Rate limit data is lost on server restart
2. Single Instance Only: Not designed for distributed deployments without modification
3. Memory Growth: Long-running instances may need periodic cleanup of old entries


## Future Improvements

With more time, I would implement:

1. **Sliding Window Log Algorithm**
    - More accurate rate limiting
    - No burst at window boundaries
    - Trade-off: Higher memory usage

2. **Token Bucket Algorithm**
    - Allow controlled bursts
    - Better for bursty traffic patterns


# Test Thread Safe

````
go test -race -v ./internal/rateLimiter/...

Codebase ini thread-safe karena:
Shared state (maps) hanya diakses 1 goroutine (process())
Communication: All via channels (requests, config, resets)
Sequential processing (requests diproses 1-by-1 di queue
````

# Docker Run

````
docker build -t rate-limiter -f .dockerfile .
docker run -p 8080:8080 rate-limiter

docker stop my-rate-limiter
docker rm my-rate-limiter
````
